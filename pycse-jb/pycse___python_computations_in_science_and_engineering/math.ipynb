{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11755379",
   "metadata": {},
   "source": [
    "## Math\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caecf3a",
   "metadata": {},
   "source": [
    "### Numeric derivatives by differences\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2f9fcc",
   "metadata": {},
   "source": [
    "[derivative!numerical](derivative!numerical)\n",
    "[derivative!forward difference](derivative!forward difference)\n",
    "[derivative!backward difference](derivative!backward difference)\n",
    "[derivative!centered difference](derivative!centered difference)\n",
    "\n",
    "numpy has a function called numpy.diff() that is similar to the one found in matlab. It calculates the differences between the elements in your list, and returns a list that is one element shorter, which makes it unsuitable for plotting the derivative of a function.\n",
    "\n",
    "Loops in python are pretty slow (relatively speaking) but they are usually trivial to understand. In this script we show some simple ways to construct derivative vectors using loops. It is implied in these formulas that the data points are equally spaced. If they are not evenly spaced, you need a different approach.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75099a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "'''\n",
    "These are the brainless way to calculate numerical derivatives. They\n",
    "work well for very smooth data. they are surprisingly fast even up to\n",
    "10000 points in the vector.\n",
    "'''\n",
    "\n",
    "x = np.linspace(0.78,0.79,100)\n",
    "y = np.sin(x)\n",
    "dy_analytical = np.cos(x)\n",
    "\n",
    "'''\n",
    "lets use a forward difference method:\n",
    "that works up until the last point, where there is not\n",
    "a forward difference to use. there, we use a backward difference.\n",
    "'''\n",
    "\n",
    "tf1 = time.time()\n",
    "dyf = [0.0]*len(x)\n",
    "for i in range(len(y)-1):\n",
    "    dyf[i] = (y[i+1] - y[i])/(x[i+1]-x[i])\n",
    "#set last element by backwards difference\n",
    "dyf[-1] = (y[-1] - y[-2])/(x[-1] - x[-2])\n",
    "\n",
    "print(' Forward difference took %f seconds' % (time.time() - tf1))\n",
    "\n",
    "'''and now a backwards difference'''\n",
    "tb1 = time.time()\n",
    "dyb = [0.0]*len(x)\n",
    "#set first element by forward difference\n",
    "dyb[0] = (y[0] - y[1])/(x[0] - x[1])\n",
    "for i in range(1,len(y)):\n",
    "    dyb[i] = (y[i] - y[i-1])/(x[i]-x[i-1])\n",
    "\n",
    "print(' Backward difference took %f seconds' % (time.time() - tb1))\n",
    "\n",
    "'''and now, a centered formula'''\n",
    "tc1 = time.time()\n",
    "dyc = [0.0]*len(x)\n",
    "dyc[0] = (y[0] - y[1])/(x[0] - x[1])\n",
    "for i in range(1,len(y)-1):\n",
    "    dyc[i] = (y[i+1] - y[i-1])/(x[i+1]-x[i-1])\n",
    "dyc[-1] = (y[-1] - y[-2])/(x[-1] - x[-2])\n",
    "\n",
    "print(' Centered difference took %f seconds' % (time.time() - tc1))\n",
    "\n",
    "'''\n",
    "the centered formula is the most accurate formula here\n",
    "'''\n",
    "\n",
    "plt.plot(x,dy_analytical,label='analytical derivative')\n",
    "plt.plot(x,dyf,'--',label='forward')\n",
    "plt.plot(x,dyb,'--',label='backward')\n",
    "plt.plot(x,dyc,'--',label='centered')\n",
    "\n",
    "plt.legend(loc='lower left');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393e44f7",
   "metadata": {},
   "source": [
    "### Vectorized numeric derivatives\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b45b602",
   "metadata": {},
   "source": [
    "[derivative!vectorized](derivative!vectorized)\n",
    "Loops are usually not great for performance. Numpy offers some vectorized methods that allow us to compute derivatives without loops, although this comes at the mental cost of harder to understand syntax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8672f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0, 2 * np.pi, 100)\n",
    "y = np.sin(x)\n",
    "dy_analytical = np.cos(x)\n",
    "\n",
    "\n",
    "# we need to specify the size of dy ahead because diff returns\n",
    "#an array of n-1 elements\n",
    "dy = np.zeros(y.shape, float) #we know it will be this size\n",
    "dy[0:-1] = np.diff(y) / np.diff(x)\n",
    "dy[-1] = (y[-1] - y[-2]) / (x[-1] - x[-2])\n",
    "\n",
    "\n",
    "'''\n",
    "calculate dy by center differencing using array slices\n",
    "'''\n",
    "\n",
    "dy2 = np.zeros(y.shape, float) #we know it will be this size\n",
    "dy2[1:-1] = (y[2:] - y[0:-2]) / (x[2:] - x[0:-2])\n",
    "\n",
    "# now the end points\n",
    "dy2[0] = (y[1] - y[0]) / (x[1] - x[0])\n",
    "dy2[-1] = (y[-1] - y[-2]) / (x[-1] - x[-2])\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.plot(x,dy_analytical,label='analytical derivative')\n",
    "plt.plot(x,dy,label='forward diff')\n",
    "plt.plot(x,dy2,'k--',lw=2,label='centered diff')\n",
    "plt.legend(loc='lower left');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07f782e",
   "metadata": {},
   "source": [
    "### 2-point vs. 4-point numerical derivatives\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6f9e24",
   "metadata": {},
   "source": [
    "[derivative!4 point formula](derivative!4 point formula)\n",
    "\n",
    "If your data is very noisy, you will have a hard time getting good derivatives; derivatives tend to magnify noise. In these cases, you have to employ smoothing techniques, either implicitly by using a multipoint derivative formula, or explicitly by smoothing the data yourself, or taking the derivative of a function that has been fit to the data in the neighborhood you are interested in.\n",
    "\n",
    "Here is an example of a 4-point centered difference of some noisy data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0a70fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0, 2*np.pi, 100)\n",
    "y = np.sin(x) + 0.1 * np.random.random(size=x.shape)\n",
    "dy_analytical = np.cos(x)\n",
    "\n",
    "#2-point formula\n",
    "dyf = [0.0] * len(x)\n",
    "for i in range(len(y)-1):\n",
    "    dyf[i] = (y[i+1] - y[i])/(x[i+1]-x[i])\n",
    "#set last element by backwards difference\n",
    "dyf[-1] = (y[-1] - y[-2])/(x[-1] - x[-2])\n",
    "\n",
    "'''\n",
    "calculate dy by 4-point center differencing using array slices\n",
    "\n",
    "\\frac{y[i-2] - 8y[i-1] + 8[i+1] - y[i+2]}{12h}\n",
    "\n",
    "y[0] and y[1] must be defined by lower order methods\n",
    "and y[-1] and y[-2] must be defined by lower order methods\n",
    "'''\n",
    "\n",
    "dy = np.zeros(y.shape, float) #we know it will be this size\n",
    "h = x[1] - x[0] #this assumes the points are evenely spaced!\n",
    "dy[2:-2] = (y[0:-4] - 8 * y[1:-3] + 8 * y[3:-1] - y[4:]) / (12.0 * h)\n",
    "\n",
    "# simple differences at the end-points\n",
    "dy[0] = (y[1] - y[0])/(x[1] - x[0])\n",
    "dy[1] = (y[2] - y[1])/(x[2] - x[1])\n",
    "dy[-2] = (y[-2] - y[-3]) / (x[-2] - x[-3])\n",
    "dy[-1] = (y[-1] - y[-2]) / (x[-1] - x[-2])\n",
    "\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, dy_analytical, label='analytical derivative')\n",
    "plt.plot(x, dyf, 'r-', label='2pt-forward diff')\n",
    "plt.plot(x, dy, 'k--', lw=2, label='4pt-centered diff')\n",
    "plt.legend(loc='lower left');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316cbce5",
   "metadata": {},
   "source": [
    "### Derivatives by polynomial fitting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fd1195",
   "metadata": {},
   "source": [
    "[derivative!polynomial](derivative!polynomial)\n",
    "\n",
    "One way to reduce the noise inherent in derivatives of noisy data is to fit a smooth function through the data, and analytically take the derivative of the curve. Polynomials are especially convenient for this. The challenge is to figure out what an appropriate polynomial order is. This requires judgment and experience.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeb04c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tspan = [0, 0.1, 0.2, 0.4, 0.8, 1]\n",
    "Ca_data = [2.0081,  1.5512,  1.1903,  0.7160,  0.2562,  0.1495]\n",
    "\n",
    "p = np.polyfit(tspan, Ca_data, 3)\n",
    "plt.figure()\n",
    "plt.plot(tspan, Ca_data)\n",
    "plt.plot(tspan, np.polyval(p, tspan), 'g-')\n",
    "\n",
    "# compute derivatives\n",
    "dp = np.polyder(p)\n",
    "\n",
    "dCdt_fit = np.polyval(dp, tspan)\n",
    "\n",
    "dCdt_numeric = np.gradient(Ca_data, tspan) # 2-point deriv\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tspan, dCdt_numeric, label='numeric derivative')\n",
    "plt.plot(tspan, dCdt_fit, label='fitted derivative')\n",
    "\n",
    "t = np.linspace(min(tspan), max(tspan))\n",
    "plt.plot(t, np.polyval(dp, t), label='resampled derivative')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f17194",
   "metadata": {},
   "source": [
    "You can see a third order polynomial is a reasonable fit here. There are only 6 data points here, so any higher order risks overfitting. Here is the comparison of the numerical derivative and the fitted derivative. We have \"resampled\" the fitted derivative to show the actual shape. Note the derivative appears to go through a maximum near t = 0.9. In this case, that is probably unphysical as the data is related to the consumption of species A in a reaction. The derivative should increase monotonically to zero. The increase is an artefact of the fitting process. End points are especially sensitive to this kind of error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902762db",
   "metadata": {},
   "source": [
    "### Derivatives by fitting a function and taking the analytical derivative\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f43abc9",
   "metadata": {},
   "source": [
    "[derivative!fitting](derivative!fitting)\n",
    "A variation of a polynomial fit is to fit a model with reasonable physics. Here we fit a nonlinear function to the noisy data. The model is for the concentration vs. time in a batch reactor for a first order irreversible reaction. Once we fit the data, we take the analytical derivative of the fitted function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b2d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "tspan = np.array([0, 0.1, 0.2, 0.4, 0.8, 1])\n",
    "Ca_data = np.array([2.0081,  1.5512,  1.1903,  0.7160,  0.2562,  0.1495])\n",
    "\n",
    "def func(t, Ca0, k):\n",
    "    return Ca0 * np.exp(-k * t)\n",
    "\n",
    "\n",
    "pars, pcov = curve_fit(func, tspan, Ca_data, p0=[2, 2.3])\n",
    "\n",
    "plt.plot(tspan, Ca_data)\n",
    "plt.plot(tspan, func(tspan, *pars), 'g-')\n",
    "\n",
    "# analytical derivative\n",
    "k, Ca0 = pars\n",
    "dCdt = -k * Ca0 * np.exp(-k * tspan)\n",
    "t = np.linspace(0, 2)\n",
    "dCdt_res =  -k * Ca0 * np.exp(-k * t)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tspan, np.gradient(Ca_data, tspan), label='numerical derivative')\n",
    "plt.plot(tspan, dCdt, label='analytical derivative of fit')\n",
    "plt.plot(t, dCdt_res, label='extrapolated')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9810882",
   "metadata": {},
   "source": [
    "Visually this fit is about the same as a third order polynomial. Note the difference in the derivative though. We can readily extrapolate this derivative and get reasonable predictions of the derivative. That is true in this case because we fitted a physically relevant model for concentration vs. time for an irreversible, first order reaction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71abbd12",
   "metadata": {},
   "source": [
    "### Derivatives by FFT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3508df05",
   "metadata": {},
   "source": [
    "[derivative!FFT](derivative!FFT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778195ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 101 #number of points\n",
    "L = 2 * np.pi #interval of data\n",
    "\n",
    "x = np.arange(0.0, L, L/float(N)) #this does not include the endpoint\n",
    "\n",
    "#add some random noise\n",
    "y = np.sin(x) + 0.05 * np.random.random(size=x.shape)\n",
    "dy_analytical = np.cos(x)\n",
    "\n",
    "'''\n",
    "http://sci.tech-archive.net/Archive/sci.math/2008-05/msg00401.html\n",
    "\n",
    "you can use fft to calculate derivatives!\n",
    "'''\n",
    "\n",
    "if N % 2 == 0:\n",
    "    k = np.asarray(list(range(0, N // 2)) + [0] + list(range(-N // 2 + 1, 0)), np.float64)\n",
    "else:\n",
    "    k = np.asarray(list(range(0, (N - 1) // 2)) + [0] + list(range(-(N - 1) // 2, 0)), np.float64)\n",
    "\n",
    "k *= 2 * np.pi / L\n",
    "\n",
    "fd = np.real(np.fft.ifft(1.0j * k * np.fft.fft(y)))\n",
    "\n",
    "plt.plot(x, y, label='function')\n",
    "plt.plot(x,dy_analytical,label='analytical der')\n",
    "plt.plot(x,fd,label='fft der')\n",
    "plt.legend(loc='lower left');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7af84f",
   "metadata": {},
   "source": [
    "### A novel way to numerically estimate the derivative of a function - complex-step derivative approximation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db8cd0f",
   "metadata": {},
   "source": [
    "[derivative!complex step](derivative!complex step)\n",
    "\n",
    "[Matlab post](http://matlab.cheme.cmu.edu/2011/12/24/a-novel-way-to-numerically-estimate-the-derivative-of-a-function-complex-step-derivative-approximation/)\n",
    "\n",
    "Adapted from [http://biomedicalcomputationreview.org/2/3/8.pdf>](http://biomedicalcomputationreview.org/2/3/8.pdf>)and\n",
    "[http://dl.acm.org/citation.cfm?id=838250.838251](http://dl.acm.org/citation.cfm?id=838250.838251)\n",
    "\n",
    "This posts introduces a novel way to numerically estimate the derivative\n",
    "of a function that does not involve finite difference schemes. Finite\n",
    "difference schemes are approximations to derivatives that become more and\n",
    "more accurate as the step size goes to zero, except that as the step size\n",
    "approaches the limits of machine accuracy, new errors can appear in the\n",
    "approximated results. In the references above, a new way to compute the\n",
    "derivative is presented that does not rely on differences!\n",
    "\n",
    "The new way is: $f'(x) = \\rm{imag}(f(x + i\\Delta x)/\\Delta x)$ where the\n",
    "function $f$ is evaluated in imaginary space with a small $\\Delta x$ in\n",
    "the complex plane. The derivative is miraculously equal to the imaginary\n",
    "part of the result in the limit of $\\Delta x \\rightarrow 0$!\n",
    "\n",
    "This example comes from the first link. The derivative must be evaluated\n",
    "using the chain rule.  We compare a forward difference, central\n",
    "difference and complex-step derivative approximations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99684c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def f(x):   return np.sin(3*x)*np.log(x)\n",
    "\n",
    "x = 0.7\n",
    "h = 1e-7\n",
    "\n",
    "# analytical derivative\n",
    "dfdx_a = 3 * np.cos( 3*x)*np.log(x) + np.sin(3*x) / x\n",
    "\n",
    "# finite difference\n",
    "dfdx_fd = (f(x + h) - f(x))/h\n",
    "\n",
    "# central difference\n",
    "dfdx_cd = (f(x+h)-f(x-h))/(2*h)\n",
    "\n",
    "# complex method\n",
    "dfdx_I = np.imag(f(x + complex(0, h))/h)\n",
    "\n",
    "print(dfdx_a)\n",
    "print(dfdx_fd)\n",
    "print(dfdx_cd)\n",
    "print(dfdx_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb4079",
   "metadata": {},
   "source": [
    "These are all the same to 4 decimal places. The simple finite difference is the least accurate, and the central differences is practically the same as the complex number approach.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdcf6f4",
   "metadata": {},
   "source": [
    "### Vectorized piecewise functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733bf844",
   "metadata": {},
   "source": [
    "[Matlab post](http://matlab.cheme.cmu.edu/2011/11/05/vectorized-piecewise-functions/)\n",
    "Occasionally we need to define piecewise functions, e.g.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "f(x) &=&  0, x < 0 \\\\\n",
    "     &=&  x, 0 <= x < 1\\\\\n",
    "     &=&  2 - x, 1 < x <= 2\\\\\n",
    "     &=&  0, x > 2\n",
    "\\end{eqnarray}\n",
    "\n",
    "Today we examine a few ways to define a function like this. A simple way is to use conditional statements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcdbefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    if x < 0:\n",
    "        return 0\n",
    "    elif (x >= 0) & (x < 1):\n",
    "        return x\n",
    "    elif (x >= 1) & (x < 2):\n",
    "        return 2.0 - x\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "print(f1(-1))\n",
    "#print(f1([0, 1, 2, 3]))  # does not work!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17e1907",
   "metadata": {},
   "source": [
    "This works, but the function is not vectorized, i.e. f([-1 0 2 3]) does not evaluate properly (it should give a list or array). You can get vectorized behavior by using list comprehension, or by writing your own loop. This does not fix all limitations, for example you cannot use the f1 function in the quad function to integrate it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ba72ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(-1, 3)\n",
    "y = [f1(xx) for xx in x]\n",
    "\n",
    "plt.plot(x, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0cda19",
   "metadata": {},
   "source": [
    "Neither of those methods is convenient. It would be nicer if the function was vectorized, which would allow the direct notation f1([0, 1, 2, 3, 4]). A simple way to achieve this is through the use of logical arrays. We create logical arrays from comparison statements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b39ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(x):\n",
    "    'fully vectorized version'\n",
    "    x = np.asarray(x)\n",
    "    y = np.zeros(x.shape)\n",
    "    y += ((x >= 0) & (x < 1)) * x\n",
    "    y += ((x >= 1) & (x < 2)) * (2 - x)\n",
    "    return y\n",
    "\n",
    "print(f2([-1, 0, 1, 2, 3, 4]))\n",
    "x = np.linspace(-1,3);\n",
    "plt.plot(x,f2(x));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ff3cb0",
   "metadata": {},
   "source": [
    "A third approach is to use Heaviside functions. The Heaviside function is defined to be zero for x less than some value, and 0.5 for x=0, and 1 for x >= 0. If you can live with y=0.5 for x=0, you can define a vectorized function in terms of Heaviside functions like this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16784ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heaviside(x):\n",
    "    x = np.array(x)\n",
    "    if x.shape != ():\n",
    "        y = np.zeros(x.shape)\n",
    "        y[x > 0.0] = 1\n",
    "        y[x == 0.0] = 0.5\n",
    "    else: # special case for 0d array (a number)\n",
    "        if x > 0: y = 1\n",
    "        elif x == 0: y = 0.5\n",
    "        else: y = 0\n",
    "    return y\n",
    "\n",
    "def f3(x):\n",
    "    x = np.array(x)\n",
    "    y1 = (heaviside(x) - heaviside(x - 1)) * x # first interval\n",
    "    y2 = (heaviside(x - 1) - heaviside(x - 2)) * (2 - x) # second interval\n",
    "    return y1 + y2\n",
    "\n",
    "from scipy.integrate import quad\n",
    "print(quad(f3, -1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d01ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, f3(x));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4195f38f",
   "metadata": {},
   "source": [
    "There are many ways to define piecewise functions, and vectorization is not always necessary. The advantages of vectorization are usually notational simplicity and speed; loops in python are usually very slow compared to vectorized functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54863ea2",
   "metadata": {},
   "source": [
    "### Smooth transitions between discontinuous functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4e3fe0",
   "metadata": {},
   "source": [
    "[original post](http://matlab.cheme.cmu.edu/2011/10/30/smooth-transitions-between-discontinuous-functions/)\n",
    "\n",
    "In [Post 1280](http://matlab.cheme.cmu.edu/2011/10/27/compute-pipe-diameter/) we used a correlation for the Fanning friction factor for turbulent flow in a pipe. For laminar flow (Re < 3000), there is another correlation that is commonly used: $f_F = 16/Re$. Unfortunately, the correlations for laminar flow and turbulent flow have different values at the transition that should occur at Re = 3000. This discontinuity can cause a lot of problems for numerical solvers that rely on derivatives.\n",
    "\n",
    "Today we examine a strategy for smoothly joining these two functions. First we define the two functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de281075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import fsolve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def fF_laminar(Re):\n",
    "    return 16.0 / Re\n",
    "\n",
    "def fF_turbulent_unvectorized(Re):\n",
    "    # Nikuradse correlation for turbulent flow\n",
    "    # 1/np.sqrt(f) = (4.0*np.log10(Re*np.sqrt(f))-0.4)\n",
    "    # we have to solve this equation to get f\n",
    "    def func(f):\n",
    "        return 1/np.sqrt(f) - (4.0*np.log10(Re*np.sqrt(f))-0.4)\n",
    "    fguess = 0.01\n",
    "    f, = fsolve(func, fguess)\n",
    "    return f\n",
    "\n",
    "# this enables us to pass vectors to the function and get vectors as\n",
    "# solutions\n",
    "fF_turbulent = np.vectorize(fF_turbulent_unvectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2eb46",
   "metadata": {},
   "source": [
    "Now we plot the correlations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41273a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Re1 = np.linspace(500, 3000)\n",
    "f1 = fF_laminar(Re1)\n",
    "\n",
    "Re2 = np.linspace(3000, 10000)\n",
    "f2 = fF_turbulent(Re2)\n",
    "\n",
    "plt.figure(1); plt.clf()\n",
    "plt.plot(Re1, f1, label='laminar')\n",
    "plt.plot(Re2, f2, label='turbulent')\n",
    "plt.xlabel('Re')\n",
    "plt.ylabel('$f_F$')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b5540c",
   "metadata": {},
   "source": [
    "You can see the discontinuity at Re = 3000. What we need is a method to join these two functions smoothly. We can do that with a sigmoid function.\n",
    "Sigmoid functions\n",
    "\n",
    "A sigmoid function smoothly varies from 0 to 1 according to the equation: $\\sigma(x) = \\frac{1}{1 + e^{-(x-x0)/\\alpha}}$. The transition is centered on $x0$, and $\\alpha$ determines the width of the transition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e0028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-4, 4);\n",
    "y = 1.0 / (1 + np.exp(-x / 0.1))\n",
    "plt.figure(2)\n",
    "plt.clf()\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('x'); plt.ylabel('y'); plt.title('$\\sigma(x)$');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4057b4",
   "metadata": {},
   "source": [
    "If we have two functions, $f_1(x)$ and $f_2(x)$ we want to smoothly join, we do it like this: $f(x) = (1-\\sigma(x))f_1(x) + \\sigma(x)f_2(x)$. There is no formal justification for this form of joining, it is simply a mathematical convenience to get a numerically smooth function. Other functions besides the sigmoid function could also be used, as long as they smoothly transition from 0 to 1, or from 1 to zero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e87689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fanning_friction_factor(Re):\n",
    "    '''combined, continuous correlation for the fanning friction factor.\n",
    "    the alpha parameter is chosen to provide the desired smoothness.\n",
    "    The transition region is about +- 4*alpha. The value 450 was\n",
    "    selected to reasonably match the shape of the correlation\n",
    "    function provided by Morrison (see last section of this file)'''\n",
    "    sigma =  1. / (1 + np.exp(-(Re - 3000.0) / 450.0));\n",
    "    f = (1-sigma) * fF_laminar(Re) + sigma * fF_turbulent(Re)\n",
    "    return f\n",
    "\n",
    "Re = np.linspace(500, 10000);\n",
    "f = fanning_friction_factor(Re);\n",
    "\n",
    "plt.plot(Re,f, label='smooth transition')\n",
    "plt.xlabel('Re')\n",
    "plt.ylabel('$f_F$')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f69088",
   "metadata": {},
   "source": [
    "You can see that away from the transition the combined function is practically equivalent to the original two functions. That is because away from the transition the sigmoid function is 0 or 1. Near Re = 3000 is a smooth transition from one curve to the other curve.\n",
    "\n",
    "[Morrison](http://www.chem.mtu.edu/~fmorriso/DataCorrelationForSmoothPipes2010.pdf) derived a single function for the friction factor correlation over all Re: $f = \\frac{0.0076\\left(\\frac{3170}{Re}\\right)^{0.165}}{1 + \\left(\\frac{3171}{Re}\\right)^{7.0}} + \\frac{16}{Re}$. Here we show the comparison with the approach used above. The friction factor differs slightly at high Re, because Morrison's is based on the Prandlt correlation, while the work here is based on the Nikuradse correlation. They are similar, but not the same.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259ca219",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0777555",
   "metadata": {},
   "source": [
    "The approach demonstrated here allows one to smoothly join two discontinuous functions that describe physics in different regimes, and that must transition over some range of data. It should be emphasized that the method has no physical basis, it simply allows one to create a mathematically smooth function, which could be necessary for some optimizers or solvers to work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd540f8b",
   "metadata": {},
   "source": [
    "### Smooth transitions between two constants\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0744a187",
   "metadata": {},
   "source": [
    "Suppose we have a parameter that has two different values depending on the value of a dimensionless number. For example when the dimensionless number is much less than 1, x = 2/3, and when x is much greater than 1, x = 1. We desire a smooth transition from 2/3 to 1  as a function of x to avoid discontinuities in functions of x. We will adapt the smooth transitions between functions to be a smooth transition between constants.\n",
    "\n",
    "We define our function as $x(D) = x0 + (x1 - x0)*(1 - sigma(D,w)$. We control the rate of the transition by the variable $w$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd36fdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x0 = 2.0 / 3.0\n",
    "x1 = 1.5\n",
    "\n",
    "w = 0.05\n",
    "\n",
    "D = np.linspace(0,2, 500)\n",
    "\n",
    "sigmaD = 1.0 / (1.0 + np.exp(-(1 - D) / w))\n",
    "\n",
    "x =  x0 + (x1 - x0)*(1 - sigmaD)\n",
    "\n",
    "plt.plot(D, x)\n",
    "plt.xlabel('D'); plt.ylabel('x');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a3cb2a",
   "metadata": {},
   "source": [
    "This is a nice trick to get an analytical function with continuous derivatives for a transition between two constants. You could have the transition occur at a value other than D = 1, as well by changing the argument to the exponential function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa3b2ab",
   "metadata": {},
   "source": [
    "### On the quad or trapz'd in ChemE heaven\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309ec411",
   "metadata": {},
   "source": [
    "[integration!trapezoid ](integration!trapezoid )\n",
    "[integration!quad](integration!quad)\n",
    "[Matlab post](http://matlab.cheme.cmu.edu/2011/09/12/on-the-quad-or-trapzd-in-cheme-heaven/)\n",
    "\n",
    "What is the difference between quad and trapz? The short answer is that quad integrates functions (via a function handle) using numerical quadrature, and trapz performs integration of arrays of data using the trapezoid method.\n",
    "\n",
    "Let us look at some examples. We consider the example of computing $\\int_0^2 x^3 dx$. the analytical integral is $1/4 x^4$, so we know the integral evaluates to 16/4 = 4. This will be our benchmark for comparison to the numerical methods.\n",
    "\n",
    "We use the scipy.integrate.quad command  to evaluate this $\\int_0^2 x^3 dx$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "\n",
    "ans, err = quad(lambda x: x**3, 0, 2)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c288c35",
   "metadata": {},
   "source": [
    "you can also define a function for the integrand.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdafb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "\n",
    "def integrand(x):\n",
    "    return x**3\n",
    "\n",
    "ans, err = quad(integrand, 0, 2)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4394d7",
   "metadata": {},
   "source": [
    "#### Numerical data integration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c89b1e",
   "metadata": {},
   "source": [
    "if we had numerical data like this, we use trapz to integrate it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9ef61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([0, 0.5, 1, 1.5, 2])\n",
    "y = x**3\n",
    "\n",
    "i2 = np.trapz(y, x)\n",
    "\n",
    "error = (i2 - 4) / 4\n",
    "\n",
    "print(i2, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917b2826",
   "metadata": {},
   "source": [
    "Note the integral of these vectors is greater than 4! You can see why here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f5afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.array([0, 0.5, 1, 1.5, 2])\n",
    "y = x**3\n",
    "\n",
    "x2 = np.linspace(0, 2)\n",
    "y2 = x2**3\n",
    "\n",
    "plt.plot(x, y, label='5 points')\n",
    "plt.plot(x2, y2, label='50 points')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e9b396",
   "metadata": {},
   "source": [
    "The trapezoid method is overestimating the area significantly. With more points, we get much closer to the analytical value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901459d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x2 = np.linspace(0, 2, 100)\n",
    "y2 = x2**3\n",
    "\n",
    "print(np.trapz(y2, x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0473d9",
   "metadata": {},
   "source": [
    "#### Combining numerical data with quad\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c144aad",
   "metadata": {},
   "source": [
    "You might want to combine numerical data with the quad function if you want to perform integrals easily. Let us say you are given this data:\n",
    "\n",
    "x = [0 0.5 1 1.5 2];\n",
    "y = [0    0.1250    1.0000    3.3750    8.0000];\n",
    "\n",
    "and you want to integrate this from x = 0.25 to 1.75. We do not have data in those regions, so some interpolation is going to be needed. Here is one approach.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4efb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import quad\n",
    "import numpy as np\n",
    "\n",
    "x = [0, 0.5, 1, 1.5, 2]\n",
    "y = [0,    0.1250,    1.0000,    3.3750,    8.0000]\n",
    "\n",
    "f = interp1d(x, y)\n",
    "\n",
    "# numerical trapezoid method\n",
    "xfine = np.linspace(0.25, 1.75)\n",
    "yfine = f(xfine)\n",
    "print(np.trapz(yfine, xfine))\n",
    "\n",
    "# quadrature with interpolation\n",
    "ans, err = quad(f, 0.25, 1.75)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b705bc2",
   "metadata": {},
   "source": [
    "These approaches are very similar, and both rely on linear interpolation. The second approach is simpler, and uses fewer lines of code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e8e21a",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567df0a6",
   "metadata": {},
   "source": [
    "trapz and quad are functions for getting integrals. Both can be used with numerical data if interpolation is used. The syntax for the quad and trapz function is different in scipy than in Matlab.\n",
    "\n",
    "Finally, see this [post](http://matlab.cheme.cmu.edu/2011/08/30/solving-integral-equations/) for an example of solving an integral equation using quad and fsolve.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aa27bc",
   "metadata": {},
   "source": [
    "### Polynomials in python\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2538554d",
   "metadata": {},
   "source": [
    "[Matlab post](http://matlab.cheme.cmu.edu/2011/08/01/polynomials-in-matlab/)\n",
    "\n",
    "Polynomials can be represented as a list of coefficients. For example, the polynomial $4*x^3 + 3*x^2 -2*x + 10 = 0$ can be represented as [4, 3, -2, 10]. Here are some ways to create a polynomial object, and evaluate it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d8cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ppar = [4, 3, -2, 10]\n",
    "p = np.poly1d(ppar)\n",
    "\n",
    "print(p(3))\n",
    "print(np.polyval(ppar, 3))\n",
    "\n",
    "x = 3\n",
    "print(4*x**3 + 3*x**2 -2*x + 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0cea02",
   "metadata": {},
   "source": [
    "numpy makes it easy to get the derivative and integral of a polynomial.\n",
    "\n",
    "Consider: $y = 2x^2 - 1$. We know the derivative is $4x$. Here we compute the derivative and evaluate it at x=4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5bbe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "p = np.poly1d([2, 0, -1])\n",
    "p2 = np.polyder(p)\n",
    "print(p2)\n",
    "print(p2(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe2ddc5",
   "metadata": {},
   "source": [
    "The integral of the previous polynomial is $\\frac{2}{3} x^3 - x + c$. We assume $C=0$. Let us compute the integral $\\int_2^4 2x^2 - 1 dx$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536fc4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "p = np.poly1d([2, 0, -1])\n",
    "p2 = np.polyint(p)\n",
    "print(p2)\n",
    "print(p2(4) - p2(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7b5cbe",
   "metadata": {},
   "source": [
    "One reason to use polynomials is the ease of finding all of the roots using numpy.roots.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79ff2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.roots([2, 0, -1])) # roots are +- sqrt(2)\n",
    "\n",
    "# note that imaginary roots exist, e.g. x^2 + 1 = 0 has two roots, +-i\n",
    "p = np.poly1d([1, 0, 1])\n",
    "print(np.roots(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6df8ff4",
   "metadata": {},
   "source": [
    "There are applications of polynomials in thermodynamics. The van der waal equation is a cubic polynomial $f(V) = V^3 - \\frac{p n b + n R T}{p} V^2 + \\frac{n^2 a}{p}V - \\frac{n^3 a b}{p} = 0$, where $a$ and $b$ are constants, $p$ is the pressure, $R$ is the gas constant, $T$ is an absolute temperature and $n$ is the number of moles. The roots of this equation tell you the volume of the gas at those conditions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d0ab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# numerical values of the constants\n",
    "a = 3.49e4\n",
    "b = 1.45\n",
    "p = 679.7   # pressure in psi\n",
    "T = 683     # T in Rankine\n",
    "n = 1.136   # lb-moles\n",
    "R = 10.73   # ft^3 * psi /R / lb-mol\n",
    "\n",
    "ppar = [1.0, -(p*n*b+n*R*T)/p, n**2*a/p,  -n**3*a*b/p];\n",
    "print(np.roots(ppar))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c235e4d",
   "metadata": {},
   "source": [
    "Note that only one root is real (and even then, we have to interpret 0.j as not being imaginary. Also, in a cubic polynomial, there can only be two imaginary roots). In this case that means there is only one phase present.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78500be7",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1f833d",
   "metadata": {},
   "source": [
    "Polynomials in numpy are even better than in Matlab, because you get a polynomial object that acts just like a function. Otherwise, they are functionally equivalent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f37ab8",
   "metadata": {},
   "source": [
    "### Wilkinson's polynomial\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f230a49",
   "metadata": {},
   "source": [
    "CLOSED: <span class=\"timestamp-wrapper\"><span class=\"timestamp\">[2014-02-21 Fri 09:55]</span></span>\n",
    "\n",
    ":categories: polynomial\n",
    ":date:     2014/02/21 09:54:47\n",
    ":updated:  2014/02/21 09:55:18\n",
    "\n",
    "[Wilkinson's polynomial](http://en.wikipedia.org/wiki/Wilkinson%27s_polynomial) is defined as\n",
    "$  w(x) = \\prod_{i=1}^{20} (x - i) = (x-1)(x-2) \\ldots (x-20) $.\n",
    "\n",
    "This innocent looking function has 20 roots, which are 1,2,3,&#x2026;,19,20. Here is a plot of the function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "@np.vectorize\n",
    "def wilkinson(x):\n",
    "    p = np.prod(np.array([x - i for i in range(1, 21)]))\n",
    "    return p\n",
    "\n",
    "x = np.linspace(0, 21, 1000)\n",
    "plt.plot(x, wilkinson(x))\n",
    "plt.ylim([-5e13, 5e13]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd8ea33",
   "metadata": {},
   "source": [
    "Let us consider the expanded version of the polynomial. We will use sympy to expand the polynomial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7073940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import Symbol, Poly\n",
    "from sympy.polys.polytools import   poly_from_expr\n",
    "\n",
    "x = Symbol('x')\n",
    "W = 1\n",
    "for i in range(1, 21):\n",
    "    W = W * (x-i)\n",
    "\n",
    "print(W.expand())\n",
    "\n",
    "P,d = poly_from_expr(W.expand())\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4700c7fa",
   "metadata": {},
   "source": [
    "The coefficients are orders of magnitude apart in size. This should make you nervous, because the roots of this equation are between 1-20, but there are numbers here that are O(19). This is likely to make any rounding errors in the number representations very significant, and may lead to issues with accuracy of the solution. Let us explore that.\n",
    "\n",
    "We will get the roots using numpy.roots.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa6c114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sympy import Symbol\n",
    "from sympy.polys.polytools import   poly_from_expr\n",
    "\n",
    "x = Symbol('x')\n",
    "W = 1\n",
    "for i in range(1, 21):\n",
    "    W = W * (x-i)\n",
    "\n",
    "P,d = poly_from_expr(W.expand())\n",
    "p = P.all_coeffs()\n",
    "x = np.arange(1, 21)\n",
    "print('\\nThese are the known roots\\n',x)\n",
    "\n",
    "# evaluate the polynomial at the known roots\n",
    "print('\\nThe polynomial evaluates to {0} at the known roots'.format(np.polyval(p, x)))\n",
    "\n",
    "# find the roots ourselves\n",
    "roots = np.roots(p)\n",
    "print('\\nHere are the roots from numpy:\\n', roots)\n",
    "\n",
    "# evaluate solution at roots\n",
    "print('\\nHere is the polynomial evaluated at the calculated roots:\\n', np.polyval(p, roots))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16672223",
   "metadata": {},
   "source": [
    "The roots are not exact. Even more to the point, the polynomial does not evaluate to zero at the calculated roots! Something is clearly wrong here. The polynomial function is fine, and it does evaluate to zero at the known roots which are integers. It is subtle, but up to that point, we are using only integers, which can be represented exactly. The roots function is evidently using some float math, and the floats are not the same as the integers.\n",
    "\n",
    "If we simply change the roots to floats, and reevaluate our polynomial, we get dramatically different results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16cc5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sympy import Symbol\n",
    "from sympy.polys.polytools import   poly_from_expr\n",
    "\n",
    "x = Symbol('x')\n",
    "W = 1\n",
    "for i in range(1, 21):\n",
    "    W = W * (x - i)\n",
    "\n",
    "P, d = poly_from_expr(W.expand())\n",
    "p = P.all_coeffs()\n",
    "x = np.arange(1, 21, dtype=np.float)\n",
    "print('\\nThese are the known roots\\n',x)\n",
    "\n",
    "# evaluate the polynomial at the known roots\n",
    "print('\\nThe polynomial evaluates to {0} at the known roots'.format(np.polyval(p, x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cb962e",
   "metadata": {},
   "source": [
    "This also happens if we make the polynomial coefficients floats. That happens because in Python whenever one element is a float the results of math operations with that element are floats.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e733f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sympy import Symbol\n",
    "from sympy.polys.polytools import   poly_from_expr\n",
    "\n",
    "x = Symbol('x')\n",
    "W = 1\n",
    "for i in range(1, 21):\n",
    "    W = W * (x - i)\n",
    "\n",
    "P,d = poly_from_expr(W.expand())\n",
    "p = [float(x) for x in P.all_coeffs()]\n",
    "x = np.arange(1, 21)\n",
    "print('\\nThese are the known roots\\n',x)\n",
    "\n",
    "# evaluate the polynomial at the known roots\n",
    "print('\\nThe polynomial evaluates to {0} at the known roots'.format(np.polyval(p, x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e991de3a",
   "metadata": {},
   "source": [
    "Let us try to understand what is happening here. It turns out that the integer and float representations of the numbers are different! It is known that you cannot exactly represent numbers as floats.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d963ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sympy import Symbol\n",
    "from sympy.polys.polytools import   poly_from_expr\n",
    "\n",
    "x = Symbol('x')\n",
    "W = 1\n",
    "for i in range(1, 21):\n",
    "    W = W * (x - i)\n",
    "\n",
    "P, d = poly_from_expr(W.expand())\n",
    "p = P.all_coeffs()\n",
    "print(p)\n",
    "print('{0:<30s}{1:<30s}{2}'.format('Integer','Float','\\delta'))\n",
    "for pj in p:\n",
    "    print('{0:<30d}{1:<30f}{2:3e}'.format(int(pj), float(pj), int(pj) - float(pj)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f837265c",
   "metadata": {},
   "source": [
    "Now you can see the issue. Many of these numbers are identical in integer and float form, but some of them are not. The integer *cannot* be exactly represented as a float, and there is a difference in the representations. It is a small difference compared to the magnitude, but these kinds of differences get raised to high powers, and become larger. You may wonder why I used \"0:<30s>\" to print the integer? That is because `pj` in that loop is an object from sympy, which prints as a string.\n",
    "\n",
    "This is a famous, and well known problem that is especially bad for this case. This illustrates that you cannot simply rely on what a computer tells you the answer is, without doing some critical thinking about the problem and the solution. Especially in problems where there are coefficients that vary by many orders of magnitude you should be cautious.\n",
    "\n",
    "There are a few interesting webpages on this topic, which inspired me to work this out in python. These webpages go into more detail on this problem, and provide additional insight into the sensitivity of the solutions to the polynomial coefficients.\n",
    "\n",
    "1.  [http://blogs.mathworks.com/cleve/2013/03/04/wilkinsons-polynomials/](http://blogs.mathworks.com/cleve/2013/03/04/wilkinsons-polynomials/)\n",
    "2.  [http://www.numericalexpert.com/blog/wilkinson_polynomial/](http://www.numericalexpert.com/blog/wilkinson_polynomial/)\n",
    "3.  [http://en.wikipedia.org/wiki/Wilkinson%27s_polynomial](http://en.wikipedia.org/wiki/Wilkinson%27s_polynomial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e69aa9f",
   "metadata": {},
   "source": [
    "### The trapezoidal method of integration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7188ee27",
   "metadata": {},
   "source": [
    "[Matlab post](http://matlab.cheme.cmu.edu/2011/10/14/the-trapezoidal-method-of-integration/)\n",
    "[integration:trapz](integration:trapz)\n",
    "See [http://en.wikipedia.org/wiki/Trapezoidal_rule](http://en.wikipedia.org/wiki/Trapezoidal_rule)\n",
    "\n",
    "$$\\int_a^b f(x) dx \\approx \\frac{1}{2}\\displaystyle\\sum\\limits_{k=1}^N(x_{k+1}-x_k)(f(x_{k+1}) + f(x_k))$$\n",
    "\n",
    "Let us compute the integral of sin(x) from x=0 to $\\pi$. To approximate the integral, we need to divide the interval from $a$ to $b$ into $N$ intervals. The analytical answer is 2.0.\n",
    "\n",
    "We will use this example to illustrate the difference in performance between loops and vectorized operations in python.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c5b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "a = 0.0; b = np.pi;\n",
    "N = 1000; # this is the number of intervals\n",
    "\n",
    "h = (b - a)/N; # this is the width of each interval\n",
    "x = np.linspace(a, b, N)\n",
    "y = np.sin(x); # the sin function is already vectorized\n",
    "\n",
    "t0 = time.time()\n",
    "f = 0.0\n",
    "for k in range(len(x) - 1):\n",
    "    f += 0.5 * ((x[k+1] - x[k]) * (y[k+1] + y[k]))\n",
    "\n",
    "tf = time.time() - t0\n",
    "print('time elapsed = {0} sec'.format(tf))\n",
    "\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433b924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "Xk = x[1:-1] - x[0:-2] # vectorized version of (x[k+1] - x[k])\n",
    "Yk = y[1:-1] + y[0:-2] # vectorized version of (y[k+1] + y[k])\n",
    "\n",
    "f = 0.5 * np.sum(Xk * Yk) # vectorized version of the loop above\n",
    "tf = time.time() - t0\n",
    "print('time elapsed = {0} sec'.format(tf))\n",
    "\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9922e73",
   "metadata": {},
   "source": [
    "In the last example, there may be loop buried in the sum command. Let us do one final method, using linear algebra, in a single line. The key to understanding this is to recognize the sum is just the result of a dot product of the x differences and y sums.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805cec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "f = 0.5 * np.dot(Xk, Yk)\n",
    "tf = time.time() - t0\n",
    "print('time elapsed = {0} sec'.format(tf))\n",
    "\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7239d1b0",
   "metadata": {},
   "source": [
    "The loop method is straightforward to code, and looks alot like the formula that defines the trapezoid method. the vectorized methods are not as easy to read, and take fewer lines of code to write. However, the vectorized methods are much faster than the loop, so the loss of readability could be worth it for very large problems.\n",
    "\n",
    "The times here are considerably slower than in Matlab. I am not sure if that is a totally fair comparison. Here I am running python through emacs, which may result in slower performance. I also used a very crude way of timing the performance which lumps some system performance in too.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ef55d5",
   "metadata": {},
   "source": [
    "### Numerical Simpsons rule\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d852583",
   "metadata": {},
   "source": [
    "[integration!Simpson's rule](integration!Simpson's rule)\n",
    "A more accurate numerical integration than the trapezoid method is [Simpson's rule](http://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.simps.html). The syntax is similar to trapz, but the method is in scipy.integrate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6acc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import simps, romb\n",
    "\n",
    "a = 0.0; b = np.pi / 4.0;\n",
    "N = 10  # this is the number of intervals\n",
    "\n",
    "x = np.linspace(a, b, N)\n",
    "y = np.cos(x)\n",
    "\n",
    "t = np.trapz(y, x)\n",
    "s = simps(y, x)\n",
    "a = np.sin(b) - np.sin(a)\n",
    "\n",
    "print('trapz = {0} ({1:%} error)'.format(t, (t - a)/a))\n",
    "print('simps = {0} ({1:%} error)'.format(s, (s - a)/a))\n",
    "print('analy = {0}'.format(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd52d03",
   "metadata": {},
   "source": [
    "You can see the Simpson's method is more accurate than the trapezoid method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec079b5",
   "metadata": {},
   "source": [
    "### Integrating functions in python\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43336ddb",
   "metadata": {},
   "source": [
    "[Matlab post](http://matlab.cheme.cmu.edu/2011/08/01/integrating-functions-in-matlab/)\n",
    "\n",
    "**Problem statement**\n",
    "\n",
    "find the integral of a function f(x) from a to b i.e.\n",
    "\n",
    "$$\\int_a^b f(x) dx$$\n",
    "\n",
    "In python we use numerical quadrature to achieve this with the scipy.integrate.quad command.\n",
    "\n",
    "as a specific example, lets integrate\n",
    "\n",
    "$$y=x^2$$\n",
    "\n",
    "from x=0 to x=1. You should be able to work out that the answer is 1/3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cfd1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "\n",
    "def integrand(x):\n",
    "    return x**2\n",
    "\n",
    "ans, err = quad(integrand, 0, 1)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdab119a",
   "metadata": {},
   "source": [
    "#### double integrals\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ededb7eb",
   "metadata": {},
   "source": [
    "we use the scipy.integrate.dblquad command\n",
    "\n",
    "Integrate $f(x,y)=y sin(x)+x cos(y)$ over\n",
    "\n",
    "$\\pi <= x <= 2\\pi$\n",
    "\n",
    "$0 <= y <= \\pi$\n",
    "\n",
    "i.e.\n",
    "\n",
    "$\\int_{x=\\pi}^{2\\pi}\\int_{y=0}^{\\pi}y sin(x)+x cos(y)dydx$\n",
    "\n",
    "The syntax in dblquad is a bit more complicated than in Matlab. We have to provide callable functions for the range of the y-variable. Here they are constants, so we create lambda functions that return the constants. Also, note that the order of arguments in the integrand is different than in Matlab.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0885237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import dblquad\n",
    "import numpy as np\n",
    "\n",
    "def integrand(y, x):\n",
    "    'y must be the first argument, and x the second.'\n",
    "    return y * np.sin(x) + x * np.cos(y)\n",
    "\n",
    "ans, err = dblquad(integrand, np.pi, 2*np.pi,\n",
    "\t\t   lambda x: 0,\n",
    "\t\t   lambda x: np.pi)\n",
    "print (ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfba3a2d",
   "metadata": {},
   "source": [
    "we use the tplquad command  to integrate $f(x,y,z)=y sin(x)+z cos(x)$ over the region\n",
    "\n",
    "$0 <= x <= \\pi$\n",
    "\n",
    "$0 <= y <= 1$\n",
    "\n",
    "$-1 <= z <= 1$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import tplquad\n",
    "import numpy as np\n",
    "\n",
    "def integrand(z, y, x):\n",
    "    return y * np.sin(x) + z * np.cos(x)\n",
    "\n",
    "ans, err = tplquad(integrand,\n",
    "                   0, np.pi,  # x limits\n",
    "                   lambda x: 0,\n",
    "                   lambda x: 1, # y limits\n",
    "                   lambda x,y: -1,\n",
    "                   lambda x,y: 1) # z limits\n",
    "\n",
    "print (ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911ab273",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c514c5",
   "metadata": {},
   "source": [
    "scipy.integrate offers the same basic functionality as Matlab does. The syntax differs significantly for these simple examples, but the use of functions for the limits enables freedom to integrate over non-constant limits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0bb9a7",
   "metadata": {},
   "source": [
    "### Integrating equations in Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c55fa0",
   "metadata": {},
   "source": [
    "A common need in engineering calculations is to integrate an equation over some range to determine the total change. For example, say we know the volumetric flow changes with time according to $d\\nu/dt = \\alpha t$, where $\\alpha = 1$ L/min and we want to know how much liquid flows into a tank over 10 minutes if the volumetric flowrate is $\\nu_0 = 5$ L/min at $t=0$. The answer to that question is the value of this integral: $V = \\int_0^{10} \\nu_0 + \\alpha t dt$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.integrate import quad\n",
    "\n",
    "nu0 = 5     # L/min\n",
    "alpha = 1.0 # L/min\n",
    "def integrand(t):\n",
    "    return nu0 + alpha * t\n",
    "\n",
    "t0 = 0.0\n",
    "tfinal = 10.0\n",
    "V, estimated_error = quad(integrand, t0, tfinal)\n",
    "print('{0:1.2f} L flowed into the tank over 10 minutes'.format(V))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25136aa8",
   "metadata": {},
   "source": [
    "That is all there is too it!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b98a34",
   "metadata": {},
   "source": [
    "### Function integration by the Romberg method\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5163c31c",
   "metadata": {},
   "source": [
    "An alternative to the scipy.integrate.quad function is the [Romberg method](http://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.romberg.html). This method is not likely to be more accurate than quad, and it does not give you an error estimate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f253a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.integrate import quad, romberg\n",
    "\n",
    "a = 0.0\n",
    "b = np.pi / 4.0\n",
    "\n",
    "print(quad(np.sin, a, b))\n",
    "print(romberg(np.sin, a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d7a7fa",
   "metadata": {},
   "source": [
    "### Symbolic math in python\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec7f61",
   "metadata": {},
   "source": [
    "[Matlab post](http://matlab.cheme.cmu.edu/2011/08/10/symbolic-math-in-matlab/)\n",
    "Python has capability to do symbolic math through the sympy package.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4001867d",
   "metadata": {},
   "source": [
    "#### Solve the quadratic equation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import solve, symbols, pprint\n",
    "\n",
    "a, b, c, x = symbols('a,b,c,x')\n",
    "\n",
    "f = a*x**2 + b*x + c\n",
    "\n",
    "solution = solve(f, x)\n",
    "print(solution)\n",
    "pprint(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8945c0f0",
   "metadata": {},
   "source": [
    "The solution you should recognize in the form of $\\frac{b \\pm \\sqrt{b^2 - 4 a c}}{2 a}$ although python does not print it this nicely!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce7c1fb",
   "metadata": {},
   "source": [
    "#### differentiation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a21b7f9",
   "metadata": {},
   "source": [
    "you might find this helpful!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c3e20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import diff\n",
    "\n",
    "print(diff(f, x))\n",
    "print(diff(f, x, 2))\n",
    "\n",
    "print(diff(f, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c52e02",
   "metadata": {},
   "source": [
    "#### integration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f04196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import integrate\n",
    "\n",
    "print(integrate(f, x))          # indefinite integral\n",
    "print(integrate(f, (x, 0, 1)))  # definite integral from x=0..1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c7e62c",
   "metadata": {},
   "source": [
    "#### Analytically solve a simple ODE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import Function, Symbol, dsolve\n",
    "f = Function('f')\n",
    "x = Symbol('x')\n",
    "fprime = f(x).diff(x) - f(x) # f' = f(x)\n",
    "\n",
    "y = dsolve(fprime, f(x))\n",
    "\n",
    "print(y)\n",
    "print(y.subs(x,4))\n",
    "print([y.subs(x, X) for X in [0, 0.5, 1]]) # multiple values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27c1b95",
   "metadata": {},
   "source": [
    "It is not clear you can solve the initial value problem to get C1.\n",
    "\n",
    "The symbolic math in sympy is pretty good. It is not up to the capability of Maple or Mathematica, (but neither is Matlab) but it continues to be developed, and could be helpful in some situations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b81852d",
   "metadata": {},
   "source": [
    "### Is your ice cream float bigger than mine\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503dbca4",
   "metadata": {},
   "source": [
    "Float numbers (i.e. the ones with decimals) cannot be perfectly represented in a computer. This can lead to some artifacts when you have to compare float numbers that on paper should be the same, but in silico are not. Let us look at some examples. In this example, we do some simple math that should result in an answer of 1, and then see if the answer is \"equal\" to one.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca91fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(3.0 * (1.0/3.0))\n",
    "print(1.0 == 3.0 * (1.0/3.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3822fa3",
   "metadata": {},
   "source": [
    "Everything looks fine. Now, consider this example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3ce4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(49.0 * (1.0/49.0))\n",
    "print(1.0 == 49.0 * (1.0/49.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad3532b",
   "metadata": {},
   "source": [
    "The first line shows the result is not 1.0, and the equality fails!\n",
    "You can see here why the equality statement fails. We will print the two numbers to sixteen decimal places.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d4cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{0:1.16f}'.format(49.0 * (1.0 / 49.0) ))\n",
    "print('{0:1.16f}'.format(1.0))\n",
    "print(1 - 49.0 * (1.0 / 49.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbd8b80",
   "metadata": {},
   "source": [
    "The two numbers actually are not equal to each other because of float math. They are *very, very* close to each other, but not the same.\n",
    "\n",
    "This leads to the idea of asking if two numbers are equal to each other within some tolerance. The question of what tolerance to use requires thought. Should it be an absolute tolerance? a relative tolerance? How large should the tolerance be? We will use the distance between 1 and the nearest floating point number (this is `eps` in Matlab). `numpy` can tell us this number with the `np.spacing` command.\n",
    "\n",
    "Below, we implement a comparison function from [doi:10.1107/S010876730302186X](http://dx.doi.org/10.1107/S010876730302186X) that allows comparisons with tolerance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6c1fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemented from Acta Crystallographica A60, 1-6 (2003). doi:10.1107/S010876730302186X\n",
    "\n",
    "import numpy as np\n",
    "print(np.spacing(1))\n",
    "\n",
    "def feq(x, y, epsilon):\n",
    "    'x == y'\n",
    "    return not((x < (y - epsilon)) or (y < (x - epsilon)))\n",
    "\n",
    "print(feq(1.0, 49.0 * (1.0/49.0), np.spacing(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6460c0",
   "metadata": {},
   "source": [
    "For completeness, here are the other float comparison operators from that paper. We also show a few examples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bd095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def flt(x, y, epsilon):\n",
    "    'x < y'\n",
    "    return x < (y - epsilon)\n",
    "\n",
    "def fgt(x, y, epsilon):\n",
    "    'x > y'\n",
    "    return y < (x - epsilon)\n",
    "\n",
    "def fle(x, y, epsilon):\n",
    "    'x <= y'\n",
    "    return not(y < (x - epsilon))\n",
    "\n",
    "def fge(x, y, epsilon):\n",
    "    'x >= y'\n",
    "    return not(x < (y - epsilon))\n",
    "\n",
    "print(fge(1.0, 49.0 * (1.0/49.0), np.spacing(1)))\n",
    "print(fle(1.0, 49.0 * (1.0/49.0), np.spacing(1)))\n",
    "\n",
    "print(fgt(1.0 + np.spacing(1), 49.0 * (1.0/49.0), np.spacing(1)))\n",
    "print(flt(1.0 - 2 * np.spacing(1), 49.0 * (1.0/49.0), np.spacing(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf00684",
   "metadata": {},
   "source": [
    "As you can see, float comparisons can be tricky. You have to give a lot of thought to how to make the comparisons, and the functions shown above are not the only way to do it. You need to build in testing to make sure your comparisons are doing what you want.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}